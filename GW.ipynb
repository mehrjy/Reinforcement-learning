{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f05b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridWorld v1.0\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "\n",
    "class GridWorld(object):\n",
    "    def __init__(self, m = 20, n = 20, foodNumber = 8, agentsNumber = 4):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.foodNumber = foodNumber\n",
    "        self.agentsNumber = agentsNumber\n",
    "        \n",
    "        self.grid = np.zeros((m, n))\n",
    "        self.foodLocation = np.random.randint(20, size=(foodNumber, 2))\n",
    "        self.setFoodsLoc(self.foodLocation)\n",
    "        # self.setFoods(foodNumber)\n",
    "        self.agentAttribute = {}\n",
    "        self.agentAttribute = self.setAgents(agentsNumber)\n",
    "        self.possibleActions = ['up', 'down', 'left', 'right', 'eat', 'attack', 'attacked']\n",
    "\n",
    "\n",
    "    def setFoodsLoc(self, foodLocation):\n",
    "        for i in range(len(foodLocation)):\n",
    "            xPos = foodLocation[i][0]\n",
    "            yPos = foodLocation[i][1]\n",
    "            if self.grid[xPos][yPos] == 0:\n",
    "                self.grid[xPos][yPos] = 10\n",
    "            else:\n",
    "                i -=1\n",
    "\n",
    "    def setFoods(self, foodNumber):\n",
    "        # np.random.seed(2021)\n",
    "        self.foodNumber = foodNumber\n",
    "        for i in range(self.foodNumber):\n",
    "            xPos = np.random.randint(self.m)\n",
    "            yPos = np.random.randint(self.n)\n",
    "            if self.grid[xPos][yPos] == 0:\n",
    "                self.grid[xPos][yPos] = 10\n",
    "            else:\n",
    "                i -=1\n",
    "\n",
    "    def setAgents(self, agentsNumber):\n",
    "        self.agentsNumber = agentsNumber\n",
    "        for i in range(agentsNumber):\n",
    "            xPos = np.random.randint(self.m)\n",
    "            yPos = np.random.randint(self.n)\n",
    "            if self.grid[xPos][yPos] == 0:\n",
    "                self.grid[xPos][yPos] = 1 + i\n",
    "                self.agentAttribute[i]={'xPos': xPos, 'yPos': yPos, 'reward': 0}\n",
    "            else:\n",
    "                i -=1\n",
    "        return self.agentAttribute\n",
    "\n",
    "    def step(self , action, agentID):\n",
    "        # 'attack':2, 'attacked':-4\n",
    "        reward_dict = {'up':-1, 'down':-1, 'left':-1, 'right':-1, 'eat':1, 'attack':2, 'attacked':-4, 'wrong attack':-1}\n",
    "        \n",
    "        if action == \"up\" and self.agentAttribute[agentID]['yPos'] - 1 > -1 and self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos'] - 1] == 0:\n",
    "            self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos']] = 0\n",
    "            self.agentAttribute[agentID]['yPos'] -= 1\n",
    "            self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos']] = agentID + 1\n",
    "            # print(\"agent \", agn,\" goes up\")\n",
    "            return self.agentAttribute, reward_dict['up'], self.status(self.agentAttribute) , None\n",
    "        elif action == \"down\" and self.agentAttribute[agentID]['yPos'] + 1 < 20 and self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos'] + 1] == 0:\n",
    "            self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos']] = 0\n",
    "            self.agentAttribute[agentID]['yPos'] += 1\n",
    "            self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos']] = agentID + 1\n",
    "            # print(\"agent \", agn,\" goes down\")\n",
    "            return self.agentAttribute, reward_dict['down'], self.status(self.agentAttribute) , None\n",
    "        elif action == \"right\" and self.agentAttribute[agentID]['xPos'] + 1 < 20 and self.grid[self.agentAttribute[agentID]['xPos'] + 1][self.agentAttribute[agentID]['yPos']] == 0:\n",
    "            self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos']] = 0\n",
    "            self.agentAttribute[agentID]['xPos'] += 1\n",
    "            self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos']] = agentID + 1\n",
    "            # print(\"agent \", agn,\" goes right\")\n",
    "            return self.agentAttribute, reward_dict['right'], self.status(self.agentAttribute) , None\n",
    "        elif action == \"left\" and self.agentAttribute[agentID]['xPos'] - 1 > -1 and self.grid[self.agentAttribute[agentID]['xPos'] - 1][self.agentAttribute[agentID]['yPos']] == 0:\n",
    "            self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos']] = 0\n",
    "            self.agentAttribute[agentID]['xPos'] -= 1\n",
    "            self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos']] = agentID + 1\n",
    "            # print(\"agent \", agn,\" goes left\")\n",
    "            return self.agentAttribute, reward_dict['left'], self.status(self.agentAttribute) , None\n",
    "        elif action == \"eat\":\n",
    "            # print(\"agent \", agn,\" in eat action\", self.agentAttribute[agentID], \"\\t Grid status\", self.grid[self.agentAttribute[agentID]['xPos'] - 1][self.agentAttribute[agentID]['yPos']])\n",
    "            if self.agentAttribute[agentID]['xPos'] - 1 > -1 and self.grid[self.agentAttribute[agentID]['xPos'] - 1][self.agentAttribute[agentID]['yPos']] == 10:\n",
    "                # print(\"agent \", agn,\" in eated in # 1 !!!!\", self.agentAttribute[agentID])\n",
    "                return self.agentAttribute, reward_dict['eat'], self.status(self.agentAttribute) , None\n",
    "            elif self.agentAttribute[agentID]['xPos'] + 1 < 20 and self.grid[self.agentAttribute[agentID]['xPos'] + 1][self.agentAttribute[agentID]['yPos']] == 10:\n",
    "                # print(\"agent \", agn,\" in eated in # 2 !!!!\", self.agentAttribute[agentID])\n",
    "                return self.agentAttribute, reward_dict['eat'], self.status(self.agentAttribute) , None\n",
    "            elif self.agentAttribute[agentID]['yPos'] - 1 > -1 and self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos'] - 1] == 10:\n",
    "                # print(\"agent \", agn,\" in eated in # 3 !!!!\", self.agentAttribute[agentID])\n",
    "                return self.agentAttribute, reward_dict['eat'], self.status(self.agentAttribute) , None\n",
    "            elif self.agentAttribute[agentID]['yPos'] + 1 < 20 and self.grid[self.agentAttribute[agentID]['xPos']][self.agentAttribute[agentID]['yPos'] + 1] == 10:\n",
    "                # print(\"agent \", agn,\" in eated in # 4 !!!!\", self.agentAttribute[agentID])\n",
    "                return self.agentAttribute, reward_dict['eat'], self.status(self.agentAttribute) , None\n",
    "            elif self.agentAttribute[agentID]['xPos'] - 1 > -1 and self.agentAttribute[agentID]['yPos'] - 1 > -1 and self.grid[self.agentAttribute[agentID]['xPos'] - 1 ][self.agentAttribute[agentID]['yPos'] - 1] == 10:\n",
    "                # print(\"agent \", agn,\" in eated in # 5 !!!!\", self.agentAttribute[agentID])\n",
    "                return self.agentAttribute, reward_dict['eat'], self.status(self.agentAttribute) , None\n",
    "            elif self.agentAttribute[agentID]['xPos'] - 1 > -1 and self.agentAttribute[agentID]['yPos'] + 1 < 20 and self.grid[self.agentAttribute[agentID]['xPos'] - 1 ][self.agentAttribute[agentID]['yPos'] + 1] == 10:\n",
    "                # print(\"agent \", agn,\" in eated in # 6 !!!!\", self.agentAttribute[agentID])\n",
    "                return self.agentAttribute, reward_dict['eat'], self.status(self.agentAttribute) , None\n",
    "            elif self.agentAttribute[agentID]['xPos'] + 1 < 20 and self.agentAttribute[agentID]['yPos'] - 1 > -1 and self.grid[self.agentAttribute[agentID]['xPos'] + 1 ][self.agentAttribute[agentID]['yPos'] - 1] == 10:\n",
    "                # print(\"agent \", agn,\" in eated in # 7 !!!!\", self.agentAttribute[agentID])\n",
    "                return self.agentAttribute, reward_dict['eat'], self.status(self.agentAttribute) , None\n",
    "            elif self.agentAttribute[agentID]['xPos'] + 1 < 20 and self.agentAttribute[agentID]['yPos'] + 1 < 20 and self.grid[self.agentAttribute[agentID]['xPos'] + 1 ][self.agentAttribute[agentID]['yPos'] + 1] == 10:\n",
    "                # print(\"agent \", agn,\" in eated in # 8 !!!!\", self.agentAttribute[agentID])\n",
    "                return self.agentAttribute, reward_dict['eat'], self.status(self.agentAttribute) , None\n",
    "            else:\n",
    "                # print(\"agent \", agn,\" in take another action !!!!\")\n",
    "                action = env.actionSpaceSample()\n",
    "                return self.step(action, agentID)\n",
    "\n",
    "        elif action == \"attack\":\n",
    "            for i in range(len(self.agentAttribute)):\n",
    "                if i == agentID:\n",
    "                    continue\n",
    "                if -2 < self.agentAttribute[agentID]['xPos'] - self.agentAttribute[i]['xPos'] and self.agentAttribute[agentID]['xPos'] - self.agentAttribute[i]['xPos'] < 2:\n",
    "                    if -2 < self.agentAttribute[agentID]['yPos'] - self.agentAttribute[i]['yPos'] and self.agentAttribute[agentID]['yPos'] - self.agentAttribute[i]['yPos'] < 2:\n",
    "                        # self.agentAttribute[i]['reward'] += reward_dict['attacked']\n",
    "                        # print(\"agent: \", agn,\" Attacked agent: \",i , \"!!!!\", self.agentAttribute[agentID], self.agentAttribute[i])\n",
    "                        return self.agentAttribute, reward_dict['attack'], self.status(self.agentAttribute) , {'action':'Attack','agentID': i,'reward': reward_dict['attacked']}\n",
    "            return self.agentAttribute, reward_dict['wrong attack'], self.status(self.agentAttribute) , None\n",
    "        else:\n",
    "            action = env.actionSpaceSample()\n",
    "            return self.step(action, agentID)\n",
    "\n",
    "    def status(self, agentAttribute):\n",
    "        self.agentAttribute = agentAttribute\n",
    "        if len(self.agentAttribute) < 2:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def reset(self):\n",
    "        self.grid = np.zeros((self.m, self.n))\n",
    "        self.setFoodsLoc(self.foodLocation)\n",
    "        # self.setFoods(self.foodNumber)\n",
    "        self.agentAttribute = self.setAgents(self.agentsNumber)\n",
    "        return self.agentAttribute\n",
    "\n",
    "    def render(self):\n",
    "        print('------------------------------------------')\n",
    "        for row in self.grid:\n",
    "            for col in row:\n",
    "                if col == 0:\n",
    "                    print('-', end='  ')\n",
    "                elif col == 10:\n",
    "                    print('F', end='  ')\n",
    "                elif col == 1:\n",
    "                    print('X1', end='  ')\n",
    "                elif col == 2:\n",
    "                    print('X2', end='  ')\n",
    "                elif col == 3:\n",
    "                    print('X3', end='  ')\n",
    "                elif col == 4:\n",
    "                    print('X4', end='  ')\n",
    "            print('\\n')\n",
    "        print('------------------------------------------')\n",
    "\n",
    "    def actionSpaceSample(self):\n",
    "        return np.random.choice(self.possibleActions)\n",
    "\n",
    "def maxAction(Q, agentID, r, c, actions):\n",
    "    values = np.array([Q[agentID, r, c, a] for a in actions])\n",
    "    action = np.argmax(values)\n",
    "    return actions[action]\n",
    "\n",
    "def debug(Q_last, Q):\n",
    "    for agn in range(agentsNumber):\n",
    "        for r in range(row):\n",
    "            for col in range(column):\n",
    "                if Q[agn, r, col, 'attack'] != Q_last[agn, r, col, 'attack']:\n",
    "                    print(\"agentID:\" + str(agn) + \"r:\" + str(r) + \"col:\" + str(col) +\" attack: \" + str(Q[agn, r, col, 'attack']))\n",
    "\n",
    "def log(i, episodeReward, agentsNumber, row, column, Q):\n",
    "    if i % 100 == 0:\n",
    "        print(\"Starting episode: \", i)\n",
    "        print(\"episodeReward: \", episodeReward)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        for agn in range(agentsNumber):\n",
    "            tempEat=[[0 for i in range(row)] for j in range(column)]\n",
    "            tempAttack=[[0 for i in range(row)] for j in range(column)]\n",
    "            for r in range(row):\n",
    "                for col in range(column):\n",
    "                    tempEat[r][col] = round(Q[agn, r, col, 'eat'], 1)\n",
    "                    tempAttack[r][col] = round(Q[agn, r, col, 'attack'], 1)\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            sns.heatmap(tempEat, annot=True)\n",
    "            plt.savefig(\"./log/episode_\" + str(i) + \"_agent_Eat_Behav_\" + str(agn) + \".png\")\n",
    "            plt.close()\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            sns.heatmap(tempAttack, annot=True)\n",
    "            plt.savefig(\"./log/episode_\" + str(i) + \"_agent_Attack_Behav_\" + str(agn) + \".png\")\n",
    "            plt.close()\n",
    "\n",
    "        for agn in range(agentsNumber):\n",
    "            with open(\"./log/Q_episode\" + str(i) + \"AgentID_\" + str(agn) + \".txt\", 'w') as f:\n",
    "                for r in range(row):\n",
    "                    f.write(\"\\n\")\n",
    "                    for col in range(column):\n",
    "                        for action in env.possibleActions:\n",
    "                            f.write(\"agentID:\" + str(agn) + \"r:\" + str(r) + \"col:\" + str(col) +\"action:\" + str(action) + \",\" + str(Q[agn, r, col, action]) + \"//  \")\n",
    "        \n",
    "def eval(env, Q):\n",
    "    done = False\n",
    "    episodeReward = [0 for i in range(agentsNumber)]\n",
    "    agentAttr = env.reset()\n",
    "    doneCounter = 0\n",
    "    while not done:\n",
    "        doneCounter += 1\n",
    "        for agn in agentAttr:\n",
    "            rand = np.random.random()\n",
    "            if rand < (1-EPS):\n",
    "                action = maxAction(Q, agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], env.possibleActions)\n",
    "                # print(\"action from Q function\")\n",
    "            else:\n",
    "                action = env.actionSpaceSample()\n",
    "                # print(\"action from random sample\")\n",
    "\n",
    "            # print(\"agent: \", agn, \"take action: \", action)\n",
    "            agentAttr_, reward, done, info = env.step(action, agn)\n",
    "            agentAttr = agentAttr_\n",
    "            env.render()\n",
    "            time.sleep(1)\n",
    "            if doneCounter > 30:\n",
    "                done = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # map magic squares to their connecting square\n",
    "    row = 20\n",
    "    column = 20\n",
    "    foodNumber = 8\n",
    "    agentsNumber = 4\n",
    "    episodeReward = [0 for i in range(agentsNumber)]\n",
    "    agentlist = [i for i in range(agentsNumber)]\n",
    "    env = GridWorld(row, column, foodNumber, agentsNumber)\n",
    "    # model hyperparameters\n",
    "    ALPHA = 0.01\n",
    "    GAMMA = 1.0\n",
    "    EPS = 1.0\n",
    "    if not os.path.exists('./log'):\n",
    "        os.mkdir('./log')\n",
    "    Q = {}\n",
    "    for agn in range(agentsNumber):\n",
    "        for r in range(row):\n",
    "            for col in range(column):\n",
    "                for action in env.possibleActions:\n",
    "                    Q[agn, r, col, action] = 0\n",
    "\n",
    "    episode = 10000\n",
    "    totalRewards = [0 for j in range(episode)]\n",
    "    Q_last = Q\n",
    "    \n",
    "    for i in range(episode):\n",
    "        # print([[env.agentAttribute[i]['xPos'], env.agentAttribute[i]['yPos']] for i in range(agentsNumber)])\n",
    "        # print(env.foodLocation)\n",
    "        log(i, episodeReward, agentsNumber, row, column, Q)\n",
    "        done = False\n",
    "        episodeReward = [0 for i in range(agentsNumber)]\n",
    "        agentAttr = env.reset()\n",
    "        doneCounter = 0\n",
    "        while not done:\n",
    "            doneCounter += 1\n",
    "            # print('episodeReward ', episodeReward)\n",
    "            random.shuffle(agentlist)\n",
    "            for agn in agentlist:\n",
    "                rand = np.random.random()\n",
    "                if rand < (1-EPS):\n",
    "                    action = maxAction(Q, agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], env.possibleActions) \n",
    "                else:\n",
    "                    action = env.actionSpaceSample()\n",
    "                \n",
    "                # agentAttr_, reward, done, info = env.step(action, agn)\n",
    "                # episodeReward[agn] += reward\n",
    "                # action_ = maxAction(Q, agn, agentAttr_[agn]['xPos'], agentAttr_[agn]['yPos'], env.possibleActions)\n",
    "                # Q[agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], action] = Q[agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], action] + ALPHA*(reward + GAMMA*Q[agn, agentAttr_[agn]['xPos'], agentAttr[agn]['yPos'], action_] - Q[agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], action])\n",
    "                # agentAttr = agentAttr_\n",
    "\n",
    "                agentAttr_, reward, done, info = env.step(action, agn)\n",
    "                if isinstance(info, type(None)):\n",
    "                    episodeReward[agn] += reward\n",
    "                    action_ = maxAction(Q, agn, agentAttr_[agn]['xPos'], agentAttr_[agn]['yPos'], env.possibleActions)\n",
    "                    Q[agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], action] = Q[agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], action] + ALPHA*(reward + GAMMA*Q[agn, agentAttr_[agn]['xPos'], agentAttr[agn]['yPos'], action_] - Q[agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], action])\n",
    "                    agentAttr = agentAttr_\n",
    "                else:\n",
    "                    episodeReward[info['agentID']] += info['reward']\n",
    "                    action_ = maxAction(Q, info['agentID'], agentAttr_[info['agentID']]['xPos'], agentAttr_[info['agentID']]['yPos'], env.possibleActions)\n",
    "                    Q[info['agentID'], agentAttr[info['agentID']]['xPos'], agentAttr[info['agentID']]['yPos'], action] = Q[info['agentID'], agentAttr[info['agentID']]['xPos'], agentAttr[info['agentID']]['yPos'], action] + ALPHA*(reward + GAMMA*Q[info['agentID'], agentAttr_[info['agentID']]['xPos'], agentAttr[info['agentID']]['yPos'], action_] - Q[info['agentID'], agentAttr[info['agentID']]['xPos'], agentAttr[info['agentID']]['yPos'], action])\n",
    "\n",
    "                    episodeReward[agn] += reward\n",
    "                    action_ = maxAction(Q, agn, agentAttr_[agn]['xPos'], agentAttr_[agn]['yPos'], env.possibleActions)\n",
    "                    Q[agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], action] = Q[agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], action] + ALPHA*(reward + GAMMA*Q[agn, agentAttr_[agn]['xPos'], agentAttr[agn]['yPos'], action_] - Q[agn, agentAttr[agn]['xPos'], agentAttr[agn]['yPos'], action])\n",
    "                    \n",
    "                    agentAttr = agentAttr_\n",
    "\n",
    "                if doneCounter > 100:\n",
    "                    done = True\n",
    "\n",
    "        if EPS - 2 / episode > 0:\n",
    "            EPS -= 2 / episode\n",
    "        else:\n",
    "            EPS = 0\n",
    "\n",
    "        totalRewards[i] = episodeReward\n",
    "\n",
    "    TRS = np.asarray(totalRewards)\n",
    "    for i in range(agentsNumber):\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.plot(TRS[:,i])\n",
    "        plt.savefig(\"./log/totalRewardAgent_\" + str(i) + \".png\")\n",
    "        plt.close()\n",
    "    \n",
    "    eval(env, Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
